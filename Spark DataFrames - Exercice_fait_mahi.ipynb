{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames Spark : Exercice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passons à un exercice pratique que vous allez traiter individuellement. Il est constitué de questions sur des données boursières, dans ce cas les actions de Walmart pour les années 2012-2017.\n",
    "R répondez aux questions et effectuez les tâches ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisez le fichier walmart_stock.csv pour répondre et compléter les tâches ci-dessous !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Démarrer une simple session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Charger le fichier CSV du stock Walmart, demander à Spark de déterminer les types de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'date'),\n",
       " ('Open', 'double'),\n",
       " ('High', 'double'),\n",
       " ('Low', 'double'),\n",
       " ('Close', 'double'),\n",
       " ('Volume', 'int'),\n",
       " ('Adj Close', 'double')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart = spark.read.csv('walmart_stock.csv', header=True, inferSchema=True)\n",
    "df_walmart.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quels sont les noms des colonnes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### À quoi ressemble le schéma ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprimer les 5 premières colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.date(2012, 1, 9), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004) \n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 3), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996) \n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 4), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475) \n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 5), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539) \n",
      "\n",
      "Row(Date=datetime.date(2012, 1, 6), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(df_walmart.head(5)[i-1], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisez describe() pour en savoir plus sur le DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question bonus !\n",
    "#### Il y a trop de décimales pour la moyenne et l'écart-type dans le dataframe describe(). Formatez les nombres pour qu'ils ne comportent que deux décimales. Prêtez attention aux types de données que .describe() renvoie, nous n'avons pas abordé la façon de faire ce formatage exact, mais nous avons abordé quelque chose de très similaire. [Consultez ce lien pour un indice](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.Column.cast)\n",
    "\n",
    "Si vous êtes bloqué, ne vous inquiétez  ! Nous reviendrons sur la solutionns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.sql.functions import format_number\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "df_walmart = df_walmart.select(\n",
    "    'Date',\n",
    "    round('Open', 2).cast(DoubleType()).alias('Open'),\n",
    "    round('High', 2).cast(DoubleType()).alias('High'),\n",
    "    round('Low', 2).cast(DoubleType()).alias('Low'),\n",
    "    round('Close', 2).cast(DoubleType()).alias('Close'),\n",
    "    round('Volume', 2).cast(IntegerType()).alias('Volume'),\n",
    "    round('Adj Close', 2).cast(DoubleType()).alias('Adj Close')\n",
    ")\n",
    "\n",
    "df_walmart.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------+---------+\n",
      "|      Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
      "+----------+-----+-----+-----+-----+--------+---------+\n",
      "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|\n",
      "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|\n",
      "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|\n",
      "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400|    51.46|\n",
      "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|\n",
      "|2012-01-10|59.43|59.71|58.98|59.04| 6907300|    51.49|\n",
      "|2012-01-11|59.06|59.53|59.04| 59.4| 6365600|    51.81|\n",
      "|2012-01-12|59.79| 60.0| 59.4| 59.5| 7236400|     51.9|\n",
      "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|    51.93|\n",
      "|2012-01-17|59.87|60.11|59.52|59.85| 8500000|     52.2|\n",
      "|2012-01-18|59.79|60.03|59.65|60.01| 5911400|    52.34|\n",
      "|2012-01-19|59.93|60.73|59.75|60.61| 9234600|    52.86|\n",
      "|2012-01-20|60.75|61.25|60.67|61.01|10378800|    53.21|\n",
      "|2012-01-23|60.81|60.98|60.51|60.91| 7134100|    53.13|\n",
      "|2012-01-24|60.75| 62.0|60.75|61.39| 7362800|    53.54|\n",
      "|2012-01-25|61.18|61.61|61.04|61.47| 5915800|    53.61|\n",
      "|2012-01-26| 61.8|61.84|60.77|60.97| 7436200|    53.18|\n",
      "|2012-01-27|60.86|61.12|60.54|60.71| 6287300|    52.95|\n",
      "|2012-01-30|60.47|61.32|60.35| 61.3| 7636900|    53.47|\n",
      "|2012-01-31|61.53|61.57|60.58|61.36| 9761500|    53.52|\n",
      "+----------+-----+-----+-----+-----+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|             Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|             1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean|72.35785373608894|72.83938791732918|71.91860095389515|72.38844992050863|8222093.481717011|67.23871224165353|\n",
      "| stddev| 6.76809037021648|6.768186744823553|6.744075695823193|6.756859155425468|  4519780.8431556|6.722615952565601|\n",
      "|    min|            56.39|            57.06|             56.3|            56.42|          2094900|            50.36|\n",
      "|    max|             90.8|            90.97|            89.25|            90.47|         80898100|            84.91|\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Créez un nouveau cadre de données avec une colonne appelée HV Ratio qui est le ratio du prix le plus élevé par rapport au volume d'actions échangées pour une journée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------+---------+--------------------+\n",
      "|      Date| Open| High|  Low|Close|  Volume|Adj Close|            HV Ratio|\n",
      "+----------+-----+-----+-----+-----+--------+---------+--------------------+\n",
      "|2012-01-03|59.97|61.06|59.87|60.33|12668800|    52.62|4.819714574387472E-6|\n",
      "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|    52.08|6.290848821573389...|\n",
      "|2012-01-05|59.35|59.62|58.37|59.42|12768200|    51.83|4.669413073103491E-6|\n",
      "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400|    51.46|7.367338339901356E-6|\n",
      "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|    51.62|8.915604928660188E-6|\n",
      "|2012-01-10|59.43|59.71|58.98|59.04| 6907300|    51.49|8.644477581688938E-6|\n",
      "|2012-01-11|59.06|59.53|59.04| 59.4| 6365600|    51.81| 9.35182857861003E-6|\n",
      "|2012-01-12|59.79| 60.0| 59.4| 59.5| 7236400|     51.9| 8.29141562102703E-6|\n",
      "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|    51.93|7.712211972623653E-6|\n",
      "|2012-01-17|59.87|60.11|59.52|59.85| 8500000|     52.2|7.071764705882352...|\n",
      "|2012-01-18|59.79|60.03|59.65|60.01| 5911400|    52.34|1.015495483303447...|\n",
      "|2012-01-19|59.93|60.73|59.75|60.61| 9234600|    52.86|6.576354146362592...|\n",
      "|2012-01-20|60.75|61.25|60.67|61.01|10378800|    53.21| 5.90145296180676E-6|\n",
      "|2012-01-23|60.81|60.98|60.51|60.91| 7134100|    53.13|8.547679455011844E-6|\n",
      "|2012-01-24|60.75| 62.0|60.75|61.39| 7362800|    53.54|8.420709512685392E-6|\n",
      "|2012-01-25|61.18|61.61|61.04|61.47| 5915800|    53.61|1.041448324825044...|\n",
      "|2012-01-26| 61.8|61.84|60.77|60.97| 7436200|    53.18|8.316075414862431E-6|\n",
      "|2012-01-27|60.86|61.12|60.54|60.71| 6287300|    52.95|9.721183974042911E-6|\n",
      "|2012-01-30|60.47|61.32|60.35| 61.3| 7636900|    53.47|8.029436027707578E-6|\n",
      "|2012-01-31|61.53|61.57|60.58|61.36| 9761500|    53.52|6.307432259386365E-6|\n",
      "+----------+-----+-----+-----+-----+--------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_walmart = df_walmart.withColumn(\"HV Ratio\", df_walmart[\"High\"] / df_walmart[\"Volume\"])\n",
    "df_walmart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel jour a eu lieu le pic de prix le plus élevé ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2015, 1, 13)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "df_walmart.orderBy(desc('High')).first()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelle est la moyenne de la colonne Close ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844992050863|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "df_walmart.select(avg('Close')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelles sont les valeurs maximale et minimale de la colonne Volume ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|min(volume)|max(volume)|\n",
      "+-----------+-----------+\n",
      "|    2094900|   80898100|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "df_walmart.agg(min('volume'), max('volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combien de jours le Close a-t-il été inférieur à 60 dollars ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart.filter(df_walmart['Close'] < 60).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel est le pourcentage de temps pendant lequel le cours le plus élevé a été supérieur à 80 dollars ?\n",
    "#### En d'autres termes, (Nombre de jours où le cours le plus élevé est supérieur à 80 dollars)/(Nombre total de joursdu jeue de données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.141494435612083\n"
     ]
    }
   ],
   "source": [
    "count_rows = df_walmart.filter(df_walmart['High'] > 80).count()\n",
    "total_rows = df_walmart.count()\n",
    "pour = (count_rows/total_rows)*100\n",
    "print(pour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quelle est la corrélation de Pearson entre le haut et le volume ?\n",
    "#### [Indice](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameStatFunctions.corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  corr(High, Volume)|\n",
      "+--------------------+\n",
      "|-0.33843260582148915|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "df_walmart.select(corr((df_walmart['High']), (df_walmart['Volume']))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel est le montant maximum par an ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|max(High)|\n",
      "+----+---------+\n",
      "|2015|    90.97|\n",
      "|2013|    81.37|\n",
      "|2014|    88.09|\n",
      "|2012|     77.6|\n",
      "|2016|    75.19|\n",
      "+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "df_walmart = df_walmart.withColumn('Year', year(df_walmart['Date']))\n",
    "df_walmart.groupBy('Year').max('High').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel est le cours de clôture moyen pour chaque mois civil ?\n",
    "#### En d'autres termes, pour toutes les années, quel est le prix de clôture moyen pour les mois de janvier, février, mars, etc. Votre résultat contiendra une valeur pour chacun de ces mois. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|       avg(Close)|\n",
      "+-----+-----------------+\n",
      "|    1|71.44801980198022|\n",
      "|    2|71.30680412371134|\n",
      "|    3|71.77794392523363|\n",
      "|    4|72.97361904761907|\n",
      "|    5|72.30971698113206|\n",
      "|    6|72.49537735849057|\n",
      "|    7|74.43971962616824|\n",
      "|    8|73.02981818181819|\n",
      "|    9|72.18411764705883|\n",
      "|   10|71.57854545454546|\n",
      "|   11|72.11108910891085|\n",
      "|   12|72.84792452830189|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month\n",
    "\n",
    "df_walmart = df_walmart.withColumn('month', month(df_walmart['Date']))\n",
    "df_walmart.groupBy('month').avg('Close').orderBy('month').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excellent travail !"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
